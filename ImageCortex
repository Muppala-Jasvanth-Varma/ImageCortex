import torch
import cv2
import matplotlib.pyplot as plt
from torchvision import models, transforms
from PIL import Image
COCO_LABELS = [
    "N/A", "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
    "traffic light", "fire hydrant", "N/A", "stop sign", "parking meter", "bench", "bird", "cat", "dog",
    "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "N/A", "backpack", "umbrella", "N/A",
    "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat",
    "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "N/A", "wine glass", "cup",
    "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli", "carrot", "hot dog",
    "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", "N/A", "dining table", "N/A", "toilet",
    "N/A", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", "toaster",
    "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"
]
model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()
def preprocess_image(image_path):
    image = Image.open(image_path)
    if image.mode != 'RGB':
        image = image.convert('RGB')
    transform = transforms.Compose([transforms.ToTensor()])
    return transform(image).unsqueeze(0)
def query_match(predictions, query):
    matched_objects = []
    for label, score in zip(predictions['labels'], predictions['scores']):
        if label.item() < len(COCO_LABELS):
            label_name = COCO_LABELS[label.item()]
            if query.lower() in label_name.lower() and score > 0.5:
                matched_objects.append((label_name, score.item()))
    return matched_objects
def display_results(image_path, predictions, matched_objects):
    image = cv2.imread(image_path)
    for box, label, score in zip(predictions['boxes'], predictions['labels'], predictions['scores']):
        if score > 0.5:
            x1, y1, x2, y2 = box.int().tolist()
            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)
            if label.item() < len(COCO_LABELS):
                label_name = COCO_LABELS[label.item()]
                cv2.putText(image, f"{label_name} ({score:.2f})", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    for label_name, score in matched_objects:
        print(f"Found: {label_name} with confidence {score:.2f}")
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.show()
def detect_objects_in_image(image_path, query):
    input_image = preprocess_image(image_path)
    with torch.no_grad():
        predictions = model(input_image)
    matched_objects = query_match(predictions[0], query)
    display_results(image_path, predictions[0], matched_objects)

if __name__ == "__main__":
    image_path = "W:/Computer vision/proj/hi.jpeg"
    query = "cat"
    detect_objects_in_image(image_path, query)
